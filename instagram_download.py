import os
import json
import asyncio
import aiohttp
import aiofiles
from urllib.parse import urlparse
from datetime import datetime
from rich.console import Console
from rich.progress import (
    Progress,
    BarColumn,
    DownloadColumn,
    TransferSpeedColumn,
    TimeRemainingColumn,
    TextColumn,
    FileSizeColumn,
)
from rich.panel import Panel

# --- é…ç½®åŒºåŸŸ ---
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0',
}

# ä»£ç†è®¾ç½® (å¦‚æœä¸éœ€è¦è¯·è®¾ä¸º None)
PROXY_URL = 'http://127.0.0.1:10808'

BASE_DIR = 'data/instagram'
DOWNLOAD_DIR = 'data/instagram/download'
HISTORY_FILE = 'data/instagram/download_history.json'
MAX_CONCURRENT_DOWNLOADS = 5

console = Console()


def get_human_readable_size(size_in_bytes):
    """å°†å­—èŠ‚è½¬æ¢ä¸ºäººç±»å¯è¯»æ ¼å¼"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_in_bytes < 1024.0:
            return f"{size_in_bytes:.2f} {unit}"
        size_in_bytes /= 1024.0
    return f"{size_in_bytes:.2f} TB"


class DownloadManager:
    def __init__(self):
        self.history = self.load_history()
        self.semaphore = asyncio.Semaphore(MAX_CONCURRENT_DOWNLOADS)
        self.success_post_count = 0
        self.skip_post_count = 0
        self.fail_post_count = 0
        self.total_files_downloaded = 0
        self.total_images_downloaded = 0
        self.total_videos_downloaded = 0

    def load_history(self):
        """åŠ è½½å·²ä¸‹è½½çš„å†å²è®°å½• (å­—å…¸æ ¼å¼)"""
        if os.path.exists(HISTORY_FILE):
            try:
                with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # ç¡®ä¿æ˜¯å­—å…¸æ ¼å¼
                    if isinstance(data, dict):
                        return data
                    # å…¼å®¹æ—§ç‰ˆæœ¬ set/list æ ¼å¼ï¼Œå¦‚æœæ˜¯æ—§æ ¼å¼åˆ™æ¸…ç©ºæˆ–è¿ç§»ï¼ˆè¿™é‡Œé€‰æ‹©æ¸…ç©ºé‡å»ºä»¥ä¿è¯ç»“æ„æ­£ç¡®ï¼‰
                    return {}
            except (json.JSONDecodeError, OSError):
                return {}
        return {}

    def save_history(self):
        """ä¿å­˜å†å²è®°å½•åˆ°æœ¬åœ°"""
        os.makedirs(os.path.dirname(HISTORY_FILE), exist_ok=True)
        try:
            with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
                json.dump(self.history, f, ensure_ascii=False, indent=2)
        except Exception as e:
            console.print(f"[red]ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}[/red]")

    async def download_single_file(self, session, progress, url, filepath, short_code):
        """
        ä¸‹è½½å•ä¸ªæ–‡ä»¶ã€‚
        è¿”å›: (success: bool, file_info: dict)
        """
        file_exists = os.path.exists(filepath)

        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è·å–ä¿¡æ¯
        if file_exists:
            try:
                file_size = os.path.getsize(filepath)
                return True, {
                    'size': file_size,
                    'save_time': datetime.fromtimestamp(os.path.getmtime(filepath)).strftime('%Y-%m-%d %H:%M:%S'),
                    'is_new_download': False
                }
            except OSError:
                # å¦‚æœè¯»å–æ–‡ä»¶å¤±è´¥ï¼Œè§†ä¸ºä¸å­˜åœ¨ï¼Œé‡æ–°ä¸‹è½½
                pass

        async with self.semaphore:
            filename = os.path.basename(filepath)
            task_id = progress.add_task(
                f"[cyan]ä¸‹è½½ä¸­... {filename[:15]}..",
                total=None,
                start=False
            )

            try:
                headers = HEADERS.copy()
                headers['referer'] = f'https://www.instagram.com/p/{short_code}'

                async with session.get(url, headers=headers, proxy=PROXY_URL, timeout=30) as response:
                    if response.status != 200:
                        console.print(f"[bold red]ä¸‹è½½å¤±è´¥ ({response.status})[/]: {filename}")
                        progress.remove_task(task_id)
                        return False, {}

                    total_length = int(response.headers.get('Content-Length', 0))
                    progress.update(task_id, total=total_length)
                    progress.start_task(task_id)

                    os.makedirs(os.path.dirname(filepath), exist_ok=True)

                    async with aiofiles.open(filepath, mode='wb') as f:
                        async for chunk in response.content.iter_chunked(8192):
                            await f.write(chunk)
                            progress.update(task_id, advance=len(chunk))

                    self.total_files_downloaded += 1

                    # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
                    if filename.lower().endswith('.mp4'):
                        self.total_videos_downloaded += 1
                    else:
                        self.total_images_downloaded += 1

                    progress.remove_task(task_id)

                    return True, {
                        'size': total_length,
                        'save_time': datetime.fromtimestamp(os.path.getmtime(filepath)).strftime('%Y-%m-%d %H:%M:%S'),
                        'is_new_download': True
                    }

            except Exception as e:
                console.print(f"[bold red]é”™è¯¯[/] {filename}: {e}")
                progress.remove_task(task_id)
                return False, {}

    async def process_post(self, session, progress, post_data):
        """
        å¤„ç†å•ä¸ª Postï¼šè§£æå…ƒæ•°æ®ï¼Œä¸‹è½½æ‰€æœ‰åŒ…å«çš„æ–‡ä»¶ï¼ˆå›¾ç‰‡æˆ–è§†é¢‘ï¼‰ã€‚
        åªæœ‰æ‰€æœ‰æ–‡ä»¶éƒ½æˆåŠŸï¼Œæ‰è¿”å› Post è®°å½•ä¿¡æ¯ã€‚
        """
        item = post_data['item']
        user = post_data['user']
        short_code = item['code']

        # å¦‚æœå†å²è®°å½•é‡Œå·²ç»æœ‰è¿™ä¸ª Postï¼Œä¸”æˆ‘ä»¬è®¤ä¸ºå®ƒå®Œæ•´ï¼Œåˆ™è·³è¿‡
        if short_code in self.history:
            self.skip_post_count += 1
            return

        # æå– Post å…ƒæ•°æ®
        caption_node = item.get('caption')
        desc = caption_node.get('text', '') if caption_node else ''
        timestamp = item.get('taken_at')
        create_time = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S') if timestamp else ''

        # --- æ ¸å¿ƒä¿®æ”¹ï¼šåª’ä½“èµ„æºæå–é€»è¾‘ ---

        def get_best_candidate(candidates):
            """ä»åˆ—è¡¨ä¸­æ ¹æ®åˆ†è¾¨ç‡é€‰å‡ºæœ€ä½³èµ„æº"""
            if not candidates:
                return None
            return max(candidates, key=lambda x: x.get('width', 0) * x.get('height', 0))

        candidates_to_process = []

        # ç¡®å®šéœ€è¦å¤„ç†çš„åª’ä½“èŠ‚ç‚¹åˆ—è¡¨
        media_nodes = []
        if 'carousel_media' in item and item['carousel_media']:
            # å¤šå›¾/è§†é¢‘ (Carousel)
            media_nodes = item['carousel_media']
        else:
            # å•å›¾/è§†é¢‘/Reel
            media_nodes = [item]

        # éå†æ‰€æœ‰èŠ‚ç‚¹æå–ä¸‹è½½é“¾æ¥
        for node in media_nodes:
            # 1. å°è¯•æå–å›¾ç‰‡ (å°é¢æˆ–çº¯å›¾ç‰‡)
            image_candidate = None
            if 'image_versions2' in node:
                image_candidate = get_best_candidate(node['image_versions2'].get('candidates', []))

            # 2. å°è¯•æå–è§†é¢‘
            video_candidate = None
            if 'video_versions' in node and node['video_versions']:
                video_candidate = get_best_candidate(node['video_versions'])

            # --- ç”Ÿæˆä¸‹è½½ç›®æ ‡ ---

            # ç”¨äºä¿æŒåŒå (basename) çš„åŸºç¡€åç§°
            base_filename = ""

            # A. å¤„ç†å›¾ç‰‡/å°é¢
            if image_candidate:
                # ä»å›¾ç‰‡ URL æå–åŸºç¡€æ–‡ä»¶åï¼Œä¾‹å¦‚: 123456_789.jpg -> 123456_789
                parsed_path = urlparse(image_candidate['url']).path
                base_filename = os.path.splitext(os.path.basename(parsed_path))[0]

                candidates_to_process.append({
                    'url': image_candidate['url'],
                    'width': image_candidate.get('width', 0),
                    'height': image_candidate.get('height', 0),
                    'is_video': False,
                    'duration': None,
                    'final_filename': f"{base_filename}.jpg"
                })

            # B. å¤„ç†è§†é¢‘ (å¦‚æœå­˜åœ¨)
            if video_candidate:
                # å¦‚æœæ²¡æœ‰å›¾ç‰‡æ¥æä¾› base_filename (æå°‘è§), åˆ™ç›´æ¥ä½¿ç”¨è§†é¢‘ URL çš„åå­—
                if not base_filename:
                    parsed_path = urlparse(video_candidate['url']).path
                    base_filename = os.path.splitext(os.path.basename(parsed_path))[0]

                candidates_to_process.append({
                    'url': video_candidate['url'],
                    'width': video_candidate.get('width', 0),
                    'height': video_candidate.get('height', 0),
                    'is_video': True,
                    'duration': node.get('video_duration'),
                    'final_filename': f"{base_filename}.mp4"
                })

        if not candidates_to_process:
            return

        # å‡†å¤‡ä¸‹è½½ä»»åŠ¡
        download_futures = []
        file_metadata_list = []

        for index, cand in enumerate(candidates_to_process):
            filename = cand['final_filename']
            filepath = os.path.join(DOWNLOAD_DIR, user, filename)

            # è®°å½•é¢„å®šå…ƒæ•°æ®
            file_meta = {
                "filename": filename,
                "filepath": filepath,
                "url": cand['url'],
                "resolution": f"{cand['width']}x{cand['height']}",
                "file_type": "video" if cand['is_video'] else "image",
                "duration": cand['duration'],
                # size, human_readable_size, save_time åœ¨ä¸‹è½½åè¡¥å……
            }
            file_metadata_list.append(file_meta)

            # åˆ›å»ºä¸‹è½½åç¨‹
            download_futures.append(
                self.download_single_file(session, progress, cand['url'], filepath, short_code)
            )

        # å¹¶å‘æ‰§è¡Œè¯¥ Post ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ä¸‹è½½
        results = await asyncio.gather(*download_futures)

        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ–‡ä»¶éƒ½æˆåŠŸ (success å­—æ®µ)
        all_success = all(r[0] for r in results)

        if all_success:
            final_files_list = []
            for i, (success, info) in enumerate(results):
                meta = file_metadata_list[i]
                meta['size'] = info['size']
                meta['human_readable_size'] = get_human_readable_size(info['size'])
                meta['save_time'] = info['save_time']
                final_files_list.append(meta)

                # æ‰“å°æ—¥å¿— (ä»…å¯¹æ–°ä¸‹è½½çš„æ–‡ä»¶æˆ–éœ€è¦æç¤ºçš„)
                if info.get('is_new_download'):
                    file_icon = "ğŸ¥" if meta['file_type'] == "video" else "ğŸ“·"
                    console.print(f"[green]âœ”[/] {file_icon} {user}/{meta['filename']} ({meta['human_readable_size']})")

            # æ„å»º Post å†å²è®°å½• Entry
            post_entry = {
                "username": user,
                "desc": desc,
                "create_time": create_time,
                "url": f"https://www.instagram.com/p/{short_code}",
                "file_num": len(final_files_list),
                "files": final_files_list
            }

            # æ›´æ–°å†…å­˜ä¸­çš„å†å²è®°å½•
            self.history[short_code] = post_entry
            self.success_post_count += 1
        else:
            self.fail_post_count += 1
            # console.print(f"[red]Post {short_code} éƒ¨åˆ†æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼Œä¸è®°å½•å†å²ã€‚[/red]")

    async def scan_and_download(self):
        if not os.path.exists(BASE_DIR):
            console.print(f"[red]ç›®å½•ä¸å­˜åœ¨: {BASE_DIR}[/red]")
            return

        # 1. æ‰«ææ‰€æœ‰ Post JSON
        console.print(f"[yellow]æ­£åœ¨æ‰«æ JSON æ–‡ä»¶ (ç›®å½•: {BASE_DIR})...[/yellow]")

        posts_to_process = []

        for root, dirs, files in os.walk(BASE_DIR):
            for file in files:
                # ç®€å•çš„è¿‡æ»¤ï¼šæ’é™¤é json æ–‡ä»¶
                if not file.endswith('.json'):
                    continue

                path = os.path.join(root, file)

                try:
                    user_folder = path.split(os.sep)[-2]
                except IndexError:
                    continue

                # æ’é™¤ç”¨æˆ·ä¿¡æ¯çš„ json (é€šå¸¸æ˜¯ username.json)
                if file.startswith(user_folder):
                    continue

                try:
                    with open(path, mode='r', encoding='utf8') as f:
                        item = json.load(f)
                except (json.JSONDecodeError, UnicodeDecodeError):
                    # ä»…åˆ é™¤å®Œå…¨æŸåçš„æ–‡ä»¶
                    # os.remove(path)
                    continue

                if not item or 'code' not in item:
                    continue

                posts_to_process.append({
                    'user': user_folder,
                    'item': item
                })

        console.print(f"[green]æ‰«æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(posts_to_process)} ä¸ª Postã€‚[/green]")

        # 2. å¼€å§‹å¤„ç†
        async with aiohttp.ClientSession() as session:
            with Progress(
                    TextColumn("[bold blue]{task.description}", justify="right"),
                    BarColumn(bar_width=None),
                    "[progress.percentage]{task.percentage:>3.1f}%",
                    "â€¢",
                    FileSizeColumn(),
                    "â€¢",
                    TransferSpeedColumn(),
                    "â€¢",
                    TimeRemainingColumn(),
                    console=console
            ) as progress:

                # åˆ›å»ºæ‰€æœ‰ Post ä»»åŠ¡
                # æ³¨æ„ï¼šè™½ç„¶è¿™é‡Œåˆ›å»ºäº†æ‰€æœ‰åç¨‹ï¼Œä½†åœ¨ download_single_file å†…éƒ¨æœ‰ semaphore é™åˆ¶å¹¶å‘ä¸‹è½½æ•°
                post_tasks = []
                for post_data in posts_to_process:
                    post_tasks.append(self.process_post(session, progress, post_data))

                if post_tasks:
                    await asyncio.gather(*post_tasks)

        # 3. ç»“æŸ
        self.save_history()
        self.print_summary()

    def print_summary(self):
        summary_text = (
            f"[bold green]ä»»åŠ¡å®Œæˆ![/bold green]\n"
            f"Post æˆåŠŸ/å·²å­˜: {self.success_post_count}\n"
            f"Post è·³è¿‡(å†å²å­˜åœ¨): {self.skip_post_count}\n"
            f"Post å¤±è´¥/ä¸å®Œæ•´: {self.fail_post_count}\n"
            f"æœ¬æ¬¡ä¸‹è½½æ–‡ä»¶æ•°: {self.total_files_downloaded}\n"
            f"  - å›¾ç‰‡: {self.total_images_downloaded}\n"
            f"  - è§†é¢‘: {self.total_videos_downloaded}"
        )
        console.print(Panel(summary_text, title="ä¸‹è½½ç»Ÿè®¡", expand=False))


if __name__ == "__main__":
    manager = DownloadManager()
    try:
        asyncio.run(manager.scan_and_download())
    except KeyboardInterrupt:
        console.print("[bold yellow]ç”¨æˆ·ä¸­æ–­æ“ä½œï¼Œæ­£åœ¨ä¿å­˜è¿›åº¦...[/bold yellow]")
        manager.save_history()
        console.print("[bold green]è¿›åº¦å·²ä¿å­˜ï¼Œç¨‹åºé€€å‡ºã€‚[/bold green]")
